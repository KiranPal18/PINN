{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2374412,"sourceType":"datasetVersion","datasetId":1256552}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.autograd as autograd\nfrom torch.autograd import Variable\nfrom scipy.io import loadmat\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:35:31.137431Z","iopub.execute_input":"2025-10-27T18:35:31.138024Z","iopub.status.idle":"2025-10-27T18:35:31.142262Z","shell.execute_reply.started":"2025-10-27T18:35:31.137989Z","shell.execute_reply":"2025-10-27T18:35:31.141425Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:35:31.346956Z","iopub.execute_input":"2025-10-27T18:35:31.347451Z","iopub.status.idle":"2025-10-27T18:35:31.351543Z","shell.execute_reply.started":"2025-10-27T18:35:31.347427Z","shell.execute_reply":"2025-10-27T18:35:31.350664Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"class Net(nn.Module):\n    \"\"\"Basic feedforward neural network with tanh activations.\"\"\"\n    def __init__(self, inp=2, out=1, hid=128, layers=3):\n        super().__init__()\n        net = []\n\n        # Input layer\n        net.append(nn.Linear(inp, hid))\n        net.append(nn.Tanh())\n\n        # Hidden layers\n        for _ in range(layers - 1):\n            net.append(nn.Linear(hid, hid))\n            net.append(nn.Tanh())\n\n        # Output layer\n        net.append(nn.Linear(hid, out))\n        self.net = nn.Sequential(*net)\n\n        # Weight initialization for stable training\n        for m in self.net:\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        \"\"\"Forward pass through the network\"\"\"\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:35:31.539307Z","iopub.execute_input":"2025-10-27T18:35:31.539577Z","iopub.status.idle":"2025-10-27T18:35:31.545515Z","shell.execute_reply.started":"2025-10-27T18:35:31.539554Z","shell.execute_reply":"2025-10-27T18:35:31.544680Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def burgers_pde(model, x, nu):\n    \"\"\"\n    model : neural network representing u(x,t)\n    x     : input tensor with columns [x, t]\n    nu    : viscosity constant\n    \"\"\"\n    x.requires_grad_(True)                     # enable autograd for PDE derivatives\n    u = model(x)                               # predicted u(x,t)\n    grads = autograd.grad(u, x, torch.ones_like(u), create_graph=True)[0]\n    u_x, u_t = grads[:, 0:1], grads[:, 1:2]    # first derivatives wrt x and t\n    u_xx = autograd.grad(u_x, x, torch.ones_like(u_x), create_graph=True)[0][:, 0:1]  # second derivative wrt x\n    f = u_t + u * u_x - nu * u_xx              # Burgers PDE residual\n    return f","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:35:31.721850Z","iopub.execute_input":"2025-10-27T18:35:31.722114Z","iopub.status.idle":"2025-10-27T18:35:31.727222Z","shell.execute_reply.started":"2025-10-27T18:35:31.722094Z","shell.execute_reply":"2025-10-27T18:35:31.726359Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"class PINN:\n    \"\"\"Trains network using data + PDE physics residual\"\"\"\n    def __init__(self, pde_fn, inp, out, nu=0.01/np.pi, lam_data=1.0, lam_phys=0.1):\n        self.net = Net(inp, out).to(device)       # neural network\n        self.pde_fn = pde_fn                      # PDE function (burgers_pde)\n        self.nu = nu                              # viscosity (used in Burgers')\n        self.lam_d = lam_data                     # weight for data loss\n        self.lam_p = lam_phys                     # weight for physics loss\n        self.loss_fn = nn.MSELoss()               # mean squared error\n        self.opt = torch.optim.Adam(self.net.parameters(), lr=1e-3)  # optimizer\n\n    def train(self, x_train, u_train, x_val, u_val, a_fn=None, epochs=5000, colloc=2000):\n        \"\"\"Main training loop\"\"\"\n        # convert all arrays to PyTorch tensors\n        x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n        u_train = torch.tensor(u_train, dtype=torch.float32).to(device)\n        x_val = torch.tensor(x_val, dtype=torch.float32).to(device)\n        u_val = torch.tensor(u_val, dtype=torch.float32).to(device)\n\n        best_rel = 1e9  # best validation error so far\n\n        for epoch in range(1,epochs+1):\n            self.opt.zero_grad()\n\n            # ---- Collocation points for physics loss ----\n            # randomly sample inside [min,max] range of training data\n            lb = torch.min(x_train, 0).values\n            ub = torch.max(x_train, 0).values\n            x_f = lb + (ub - lb) * torch.rand((colloc, x_train.shape[1]), device=device)\n\n            # ---- Compute physics and data losses ----\n            if a_fn is None:\n                f = self.pde_fn(self.net, x_f, self.nu)\n            else:\n                f = self.pde_fn(self.net, a_fn, x_f)\n            loss_p = self.loss_fn(f, torch.zeros_like(f))       # PDE residual loss\n            u_pred = self.net(x_train)\n            loss_d = self.loss_fn(u_pred, u_train)              # supervised data loss\n            loss = self.lam_d * loss_d + self.lam_p * loss_p    # total weighted loss\n\n            # ---- Backpropagation ----\n            loss.backward()\n            self.opt.step()\n\n            # ---- Validation every few steps ----\n            if epoch % 500 == 0 or epoch == epochs - 1:\n                self.net.eval()\n                with torch.no_grad():\n                    u_pred_val = self.net(x_val).cpu().numpy()\n                    u_val_np = u_val.detach().cpu().numpy() if torch.is_tensor(u_val) else u_val\n                rel = np.linalg.norm(u_pred_val - u_val_np) / np.linalg.norm(u_val_np)\n                print(f\"Epoch {epoch:5d} | Total {loss.item():.6e} | Data {loss_d.item():.3e} | Phys {loss_p.item():.3e} | ValRel {rel:.3e}\")\n                # save best model\n                if rel < best_rel:\n                    best_rel = rel\n                    torch.save(self.net.state_dict(), \"best_model.pt\")\n        print(f\"Best Validation Relative Error: {best_rel}\")\n\n    def predict(self, x):\n        \"\"\"Predict using trained network\"\"\"\n        x = torch.tensor(x, dtype=torch.float32).to(device)\n        self.net.eval()\n        with torch.no_grad():\n            return self.net(x).cpu().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:35:33.088453Z","iopub.execute_input":"2025-10-27T18:35:33.088737Z","iopub.status.idle":"2025-10-27T18:35:33.099800Z","shell.execute_reply.started":"2025-10-27T18:35:33.088716Z","shell.execute_reply":"2025-10-27T18:35:33.098910Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def load_burgers(path, sample_size=10000):\n    \"\"\"\n    Loads Burgers' dataset (.mat file) safely and efficiently.\n\n    - Handles both 2D (single sample) and 3D (multiple samples)\n    - Uses only the first `sample_size` samples (default 10,000)\n    - Returns flattened arrays X (x,t) and U (u)\n    \"\"\"\n    data = loadmat(path)\n    u = data[\"u\"]\n\n    # Make sure u is 3D â†’ (N, nt, nx)\n    if u.ndim == 2:\n        u = u[None, :, :]  # single sample\n    if u.shape[1] > u.shape[2]:  # transpose if needed\n        u = np.transpose(u, (0, 2, 1))\n\n    # Extract dimensions\n    n, nt, nx = u.shape\n    x = np.linspace(0, 1, nx)\n    t = np.linspace(0, 1, nt)\n    X, T = np.meshgrid(x, t)\n    X_flat, T_flat = X.ravel(), T.ravel()\n\n    # Flatten into (x, t, u)\n    X_all, U_all = [], []\n    for i in range(n):\n        Ui = u[i].ravel()[:, None]\n        Xi = np.stack([X_flat, T_flat], axis=1)\n        X_all.append(Xi)\n        U_all.append(Ui)\n\n    X_all = np.vstack(X_all)\n    U_all = np.vstack(U_all)\n\n    # Subsample to first `sample_size` points\n    if X_all.shape[0] > sample_size:\n        X_all = X_all[:sample_size]\n        U_all = U_all[:sample_size]\n    return X_all, U_all\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:35:36.153419Z","iopub.execute_input":"2025-10-27T18:35:36.153727Z","iopub.status.idle":"2025-10-27T18:35:36.159998Z","shell.execute_reply.started":"2025-10-27T18:35:36.153694Z","shell.execute_reply":"2025-10-27T18:35:36.159247Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"mode = \"burgers\"\ndata_path = \"/kaggle/input/pde-dataset/burgers_data_R10.mat\"\nepochs = 5000    # number of training epochs\n\n# Load Burgers dataset\nX, U = load_burgers(data_path, sample_size=10000)\n\n# Split into train/validation sets\nX_tr, X_val, U_tr, U_val = train_test_split(X, U, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:35:41.990529Z","iopub.execute_input":"2025-10-27T18:35:41.990846Z","iopub.status.idle":"2025-10-27T18:35:46.735154Z","shell.execute_reply.started":"2025-10-27T18:35:41.990825Z","shell.execute_reply":"2025-10-27T18:35:46.734558Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# Normalize for stability\nxm = np.nanmean(X_tr, axis=0)\nxs = np.nanstd(X_tr, axis=0) + 1e-8\num = np.nanmean(U_tr, axis=0)\nus = np.nanstd(U_tr, axis=0) + 1e-8\n\n# Replace any NaNs or infs\nX_tr = np.nan_to_num((X_tr - xm) / xs)\nX_val = np.nan_to_num((X_val - xm) / xs)\nU_tr = np.nan_to_num((U_tr - um) / us)\nU_val = np.nan_to_num((U_val - um) / us)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:35:46.736328Z","iopub.execute_input":"2025-10-27T18:35:46.736654Z","iopub.status.idle":"2025-10-27T18:35:46.750671Z","shell.execute_reply.started":"2025-10-27T18:35:46.736629Z","shell.execute_reply":"2025-10-27T18:35:46.750153Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# Create and train model\nmodel = PINN(pde_fn=burgers_pde, inp=2, out=1)\nmodel.train(X_tr, U_tr, X_val, U_val, epochs=epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:35:52.648855Z","iopub.execute_input":"2025-10-27T18:35:52.649401Z","iopub.status.idle":"2025-10-27T18:36:17.586335Z","shell.execute_reply.started":"2025-10-27T18:35:52.649380Z","shell.execute_reply":"2025-10-27T18:36:17.585551Z"}},"outputs":[{"name":"stdout","text":"Epoch   500 | Total 4.017894e-02 | Data 7.624e-03 | Phys 3.255e-01 | ValRel 7.689e-02\nEpoch  1000 | Total 3.983972e-02 | Data 6.353e-03 | Phys 3.349e-01 | ValRel 7.763e-02\nEpoch  1500 | Total 3.780898e-02 | Data 5.953e-03 | Phys 3.186e-01 | ValRel 7.807e-02\nEpoch  2000 | Total 3.756800e-02 | Data 5.407e-03 | Phys 3.216e-01 | ValRel 7.966e-02\nEpoch  2500 | Total 3.547914e-02 | Data 5.567e-03 | Phys 2.991e-01 | ValRel 7.180e-02\nEpoch  3000 | Total 3.627674e-02 | Data 5.330e-03 | Phys 3.095e-01 | ValRel 7.468e-02\nEpoch  3500 | Total 3.751700e-02 | Data 6.216e-03 | Phys 3.130e-01 | ValRel 8.758e-02\nEpoch  4000 | Total 2.638477e-02 | Data 4.821e-03 | Phys 2.156e-01 | ValRel 6.908e-02\nEpoch  4500 | Total 2.023248e-02 | Data 5.358e-03 | Phys 1.487e-01 | ValRel 6.777e-02\nEpoch  4999 | Total 2.045881e-02 | Data 4.130e-03 | Phys 1.633e-01 | ValRel 6.233e-02\nEpoch  5000 | Total 2.304295e-02 | Data 3.929e-03 | Phys 1.911e-01 | ValRel 6.801e-02\nBest Validation Relative Error: 0.06232757121324539\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
